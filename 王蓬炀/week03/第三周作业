import torch
import torch.nn as nn
import numpy as np
import random
import json


class RNNModel(nn.Module):
    def __init__(self, vector_dim, vocab_size):
        super(RNNModel, self).__init__()
        self.embedding = nn.Embedding(vocab_size, vector_dim, padding_idx=0)  # embedding层
        self.rnn = nn.LSTM(vector_dim, vector_dim, batch_first=True)  # LSTM层
        self.classify = nn.Linear(vector_dim, vocab_size)  # 输出层，类别数等于字符集大小
        self.softmax = nn.LogSoftmax(dim=1)  # softmax激活

    def forward(self, x):
        x = self.embedding(x)  # (batch_size, sentence_length, vector_dim)
        rnn_out, _ = self.rnn(x)  # (batch_size, sentence_length, vector_dim)
        # 取RNN最后一个时间步的输出
        x = rnn_out[:, -1, :]  # (batch_size, vector_dim)
        x = self.classify(x)  # (batch_size, vocab_size)
        return self.softmax(x)  # 返回每个字符的概率

# 构建字符表
def build_vocab():
    chars = "你我他defghijklmnopqrstuvwxyz"  # 字符集
    vocab = {char: idx + 1 for idx, char in enumerate(chars)}  # 映射
    vocab['pad'] = 0
    vocab['unk'] = len(vocab) + 1  # 添加未知字符
    return vocab

# 随机生成样本
def build_sample(vocab, sentence_length):
    x = [random.choice(list(vocab.keys())) for _ in range(sentence_length)]  # 随机生成句子
    target_char = "你我他"  # 要查找的字符
    y = 0  # 默认无字符
    for idx, char in enumerate(x):
        if char in target_char:
            y = idx  # 记录第一次出现的位置
            break
    if y == 0 and all(c not in x for c in target_char):
        y = -1  # 如果没有字符出现，标记为-1
    x = [vocab.get(word, vocab['unk']) for word in x]  # 将字符转换成向量
    return x, y  # 返回输入序列和目标位置

# 建立数据集
def build_dataset(sample_length, vocab, sentence_length):
    dataset_x = []
    dataset_y = []
    for _ in range(sample_length):
        x, y = build_sample(vocab, sentence_length)
        dataset_x.append(x)
        dataset_y.append(y)
    dataset_y = torch.LongTensor(dataset_y)  # 转换为LongTensor
    return torch.LongTensor(dataset_x), dataset_y

# 建立模型
def build_model(vocab, char_dim):
    model = RNNModel(char_dim, len(vocab))
    return model

# 评估模型
def evaluate(model, vocab, sample_length):
    model.eval()
    x, y = build_dataset(sample_length, vocab, sentence_length)  # 生成样本
    correct_predictions = 0
    with torch.no_grad():
        predictions = model(x)  # 获取模型的预测
        predicted_indices = torch.argmax(predictions, dim=1)  # 获取最大可能性的类别
        for pred, true in zip(predicted_indices, y):
            if true == -1 and pred != 0:  # 确保没有出现的字符被判定为0
                continue
            if pred == true:
                correct_predictions += 1  # 记录正确的预测
    accuracy = correct_predictions / sample_length
    print(f"正确预测: {correct_predictions}, 准确率: {accuracy:.4f}")
    return accuracy

def main():
    epoch_num = 10        # 训练轮数
    batch_size = 20       # 每批次样本个数
    train_sample = 500    # 每轮训练的总样本数
    char_dim = 20         # 字符的向量维度
    sentence_length = 6   # 样本文本长度
    learning_rate = 0.005 # 学习率

    vocab = build_vocab()  # 构建字符表
    model = build_model(vocab, char_dim)  # 初始化模型
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 初始化优化器
    log = []

    for epoch in range(epoch_num):
        model.train()
        total_loss = 0
        for _ in range(int(train_sample / batch_size)):
            x, y = build_dataset(batch_size, vocab, sentence_length)  # 生成数据
            optimizer.zero_grad()
            predictions = model(x)  # 模型预测
            # 进行处理，让y在0到len(vocab)-1的范围
            y[y == -1] = len(vocab) - 1  # 将-1的样本位置标记为未找到字符的位置
            loss = nn.CrossEntropyLoss()(predictions, y)  # 计算损失
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        average_loss = total_loss / (train_sample / batch_size)
        print(f"=========\n第{epoch + 1}轮平均损失: {average_loss:.4f}")
        acc = evaluate(model, vocab, 200)  # 评估模型的表现
        log.append([acc, average_loss])

    # 画图
    # plt.plot(range(len(log)), [l[0] for l in log], label="准确率")  # 画准确率曲线
    # plt.plot(range(len(log)), [l[1] for l in log], label="损失")  # 画损失曲线
    # plt.legend()
    # plt.show()

    # 保存模型和词表
    torch.save(model.state_dict(), "model_rnn.pth")
    with open("vocab.json", "w", encoding="utf8") as writer:
        json.dump(vocab, writer, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()
